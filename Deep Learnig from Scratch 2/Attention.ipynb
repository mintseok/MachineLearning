{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4ILtgICdBGHqObXohxFOG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mintseok/MachineLearning/blob/main/Deep%20Learnig%20from%20Scratch%202/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ahMm4zxinmj"
      },
      "source": [
        "# Google Drive 연동!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbuCCER9ilKz",
        "outputId": "c6a2d5d1-8742-4422-8b32-7b645e51defc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKqR5gT3BO6Z",
        "outputId": "61d3c572-e04b-47ca-a4d7-88ec15f8de48"
      },
      "source": [
        "cd /content/drive/MyDrive/밑시딥2/DLFromScratch2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/밑시딥2/DLFromScratch2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwXRA_a9FU7V"
      },
      "source": [
        "어텐션 Attention\n",
        "\n",
        "-> '도착어 단어'와 대응 관계에 있는 '출발어 단어'의 정보를 골라내는 것. 즉 필요한 정보에만 주목하여 그 정보로부터 시계열 변환을 수행하는 것이 목표"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONx4EAx9-9Sm"
      },
      "source": [
        "# Decoder 개선"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcRqVhhbiyXO"
      },
      "source": [
        "# Weight Sum\n",
        "import numpy as np\n",
        "\n",
        "class WeightSum:\n",
        "  def __init__(self):\n",
        "    self.params, self.grads = [], []\n",
        "    self.cache = None\n",
        "\n",
        "  def forward(self, hs, a):\n",
        "    N, T, H = hs.shape\n",
        "\n",
        "    ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
        "    t = hs * ar\n",
        "    c = np.sum(t, axis=1)\n",
        "\n",
        "    self.cache = (hs, ar)\n",
        "    return c\n",
        "\n",
        "  def backward(self, dc):\n",
        "    hs, ar = self.cache\n",
        "    N, T, H = hs.shape\n",
        "\n",
        "    dt = dc.reshape(N, 1, H).repeat(T, axis=1) # sum의 역전파\n",
        "    dar = dt * hs\n",
        "    dhs = dt * ar\n",
        "    da = np.sum(dar, axis=2) # repeat의 역전파\n",
        "\n",
        "    return dhs, da"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkKfPOyaAJyL"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import numpy as np\n",
        "from common.layers import Softmax\n",
        "\n",
        "class AttentionWeight:\n",
        "  def __init__(self):\n",
        "    self.params, self.grads = [], []\n",
        "    self.softmax = Softmax()\n",
        "    self.cache = None\n",
        "  \n",
        "  def forward(self, hs, h):\n",
        "    N, T, H = hs.shape\n",
        "\n",
        "    hr = h.reshape(N, 1, H).repeat(T, axis=1)\n",
        "    t = hs * hs\n",
        "    s = np.sum(t, axis=2)\n",
        "    a = self.softmax.forward(s)\n",
        "\n",
        "    self.cache = (hs, hr)\n",
        "    return a\n",
        "\n",
        "  def backward(self, da):\n",
        "    hs, hr = self.cache\n",
        "    N, T, H = hs.shape\n",
        "\n",
        "    ds = self.softmax.backward(da)\n",
        "    dt = ds.reshape(N, T, 1).repeat(H, axis=2)\n",
        "    dhs = dt * hr\n",
        "    dhr = dt * hs\n",
        "    dh = np.sum(dhr, axis=1)\n",
        "\n",
        "    return dhs, dh"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x88qxX9BZqt"
      },
      "source": [
        "# Attention\n",
        "class Attention:\n",
        "  def __init__(self):\n",
        "    self.params, self.grads = [], []\n",
        "    self.attention_weight_layer = AttentionWeight()\n",
        "    self.weight_sum_layer = WeightSum()\n",
        "    self.attention_weight = None\n",
        "  \n",
        "  def forward(self, hs, h):\n",
        "    a = self.attention_weight_layer.forward(hs, h)\n",
        "    out = self.weight_sum_layer.forward(hs, a)\n",
        "    self.attention_weight = a\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dhs0, da = self.weight_sum_layer.backward(dout)\n",
        "    dhs1, dh = self.attention_weight_layer.backward(da)\n",
        "    dhs = dhs0 + dhs1\n",
        "    return dhs, dh"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmXGsLrcBZZU"
      },
      "source": [
        "# Time Attention\n",
        "class TimeAttention:\n",
        "  def __init__(self):\n",
        "    self.params, self.grads = [], []\n",
        "    self.layers = None\n",
        "    self.attention_weights = None\n",
        "\n",
        "  def forward(self, hs_enc, hs_dec):\n",
        "    N, T, H = hs_dec.shape\n",
        "    out = np.empty_like(hs_dec)\n",
        "    self.layers = []\n",
        "    self.attention_weights = []\n",
        "\n",
        "    for t in range(T):\n",
        "      layer = Attention()\n",
        "      out[:, t, :] = layer.forward(hs_enc, hs_dec[:,t,:])\n",
        "      self.layers.append(layer)\n",
        "      self.attention_weights.append(layer.attention_weight)\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    N, T, H = dout.shape\n",
        "    dhs_enc = 0\n",
        "    dhs_dec = np.empty_like(dout)\n",
        "\n",
        "    for t in range(T):\n",
        "      layer = self.layers[t]\n",
        "      dhs, dh = layer.backward(dout[:, t, :])\n",
        "      dhs_enc += dhs\n",
        "      dhs_dec[:,t,:] = dh\n",
        "\n",
        "    return dhs_enc, dhs_dec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esq1rjTyM5ud"
      },
      "source": [
        "# Attention Encoder & Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4_1qSREMyG0"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "from common.time_layers import *\n",
        "from Chap08_Attention.seq2seq import Encoder, Seq2seq\n",
        "from Chap08_Attention.attention_layer import TimeAttention\n",
        "\n",
        "\n",
        "class AttentionEncoder(Encoder):\n",
        "    def forward(self, xs):\n",
        "        xs = self.embed.forward(xs)\n",
        "        hs = self.lstm.forward(xs)\n",
        "        return hs\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        dout = self.lstm.backward(dhs)\n",
        "        dout = self.embed.backward(dout)\n",
        "        return dout\n",
        "\n",
        "\n",
        "class AttentionDecoder:\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b = np.zeros(4 * H).astype('f')\n",
        "        affine_W = (rn(2*H, V) / np.sqrt(2*H)).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        self.embed = TimeEmbedding(embed_W)\n",
        "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
        "        self.attention = TimeAttention()  # Attention 레이어 \n",
        "        self.affine = TimeAffine(affine_W, affine_b)\n",
        "        layers = [self.embed, self.lstm, self.attention, self.affine]\n",
        "\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "    def forward(self, xs, enc_hs):\n",
        "        h = enc_hs[:,-1]\n",
        "        self.lstm.set_state(h)\n",
        "\n",
        "        out = self.embed.forward(xs)\n",
        "        dec_hs = self.lstm.forward(out)\n",
        "        c = self.attention.forward(enc_hs, dec_hs)  # context vector\n",
        "        out = np.concatenate((c, dec_hs), axis=2)  # context_vector & lstm h_t\n",
        "        score = self.affine.forward(out)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def backward(self, dscore):\n",
        "        dout = self.affine.backward(dscore)\n",
        "        N, T, H2 = dout.shape\n",
        "        H = H2 // 2\n",
        "\n",
        "        dc, ddec_hs0 = dout[:,:,:H], dout[:,:,H:]\n",
        "        denc_hs, ddec_hs1 = self.attention.backward(dc)\n",
        "        ddec_hs = ddec_hs0 + ddec_hs1\n",
        "        dout = self.lstm.backward(ddec_hs)\n",
        "        dh = self.lstm.dh\n",
        "        denc_hs[:, -1] += dh\n",
        "        self.embed.backward(dout)\n",
        "\n",
        "        return denc_hs\n",
        "\n",
        "    def generate(self, enc_hs, start_id, sample_size):\n",
        "        sampled = []\n",
        "        sample_id = start_id\n",
        "        h = enc_hs[:, -1]\n",
        "        self.lstm.set_state(h)\n",
        "\n",
        "        for _ in range(sample_size):\n",
        "            x = np.array([sample_id]).reshape((1, 1))\n",
        "\n",
        "            out = self.embed.forward(x)\n",
        "            dec_hs = self.lstm.forward(out)\n",
        "            c = self.attention.forward(enc_hs, dec_hs)\n",
        "            out = np.concatenate((c, dec_hs), axis=2)\n",
        "            score = self.affine.forward(out)\n",
        "\n",
        "            sample_id = np.argmax(score.flatten())\n",
        "            sampled.append(sample_id)\n",
        "\n",
        "        return sampled"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOhtP8p_NU9A"
      },
      "source": [
        "# Seq2Seq 구현\n",
        "class AttntionSeq2seq(Seq2seq):\n",
        "  def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "    args = vocab_size, wordvec_size, hidden_size\n",
        "    self.encoder = AttentionEncoder(*args)\n",
        "    self.decoder = AttentionDecoder(*args)\n",
        "    self.softmax = TimeSoftmaxWithLoss()\n",
        "\n",
        "    self.params = self.encoder.params + self.decoder.params\n",
        "    self.grads = self.encoder.grads + self.decoder.grads"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPSBJgwZOCFZ"
      },
      "source": [
        "# AttentionSeq2seq 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b3qT0h4iOBcc",
        "outputId": "a402abc7-b928-4b27-a2cf-97829b98b0f2"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import sequence\n",
        "from common.optimizer import Adam\n",
        "from common.trainer import Trainer\n",
        "from common.util import eval_seq2seq\n",
        "from Chap08_Attention.attention_seq2seq import AttentionSeq2seq\n",
        "from Chap07_Seq2Seq.seq2seq import Seq2seq\n",
        "from Chap07_Seq2Seq.peeky_seq2seq import PeekySeq2seq\n",
        "\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "# 입력 문장 반전\n",
        "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(char_to_id)\n",
        "wordvec_size = 16\n",
        "hidden_size = 256\n",
        "batch_size = 128\n",
        "max_epoch = 10\n",
        "max_grad = 5.0\n",
        "\n",
        "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "acc_list = []\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(x_train, t_train, max_epoch=1,\n",
        "                batch_size=batch_size, max_grad=max_grad)\n",
        "\n",
        "    correct_num = 0\n",
        "    for i in range(len(x_test)):\n",
        "        question, correct = x_test[[i]], t_test[[i]]\n",
        "        verbose = i < 10\n",
        "        correct_num += eval_seq2seq(model, question, correct,\n",
        "                                    id_to_char, verbose, is_reverse=True)\n",
        "\n",
        "    acc = float(correct_num) / len(x_test)\n",
        "    acc_list.append(acc)\n",
        "    print('정확도 %.3f%%' % (acc * 100))\n",
        "\n",
        "\n",
        "model.save_params()\n",
        "\n",
        "# 그래프 그리기\n",
        "x = np.arange(len(acc_list))\n",
        "plt.plot(x, acc_list, marker='o')\n",
        "plt.xlabel('에폭')\n",
        "plt.ylabel('정확도')\n",
        "plt.ylim(-0.05, 1.05)\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 4.08\n",
            "| 에폭 1 |  반복 21 / 351 | 시간 13[s] | 손실 3.09\n",
            "| 에폭 1 |  반복 41 / 351 | 시간 27[s] | 손실 1.90\n",
            "| 에폭 1 |  반복 61 / 351 | 시간 40[s] | 손실 1.72\n",
            "| 에폭 1 |  반복 81 / 351 | 시간 53[s] | 손실 1.46\n",
            "| 에폭 1 |  반복 101 / 351 | 시간 66[s] | 손실 1.19\n",
            "| 에폭 1 |  반복 121 / 351 | 시간 79[s] | 손실 1.14\n",
            "| 에폭 1 |  반복 141 / 351 | 시간 92[s] | 손실 1.09\n",
            "| 에폭 1 |  반복 161 / 351 | 시간 105[s] | 손실 1.06\n",
            "| 에폭 1 |  반복 181 / 351 | 시간 118[s] | 손실 1.04\n",
            "| 에폭 1 |  반복 201 / 351 | 시간 130[s] | 손실 1.03\n",
            "| 에폭 1 |  반복 221 / 351 | 시간 143[s] | 손실 1.02\n",
            "| 에폭 1 |  반복 241 / 351 | 시간 156[s] | 손실 1.02\n",
            "| 에폭 1 |  반복 261 / 351 | 시간 169[s] | 손실 1.01\n",
            "| 에폭 1 |  반복 281 / 351 | 시간 182[s] | 손실 1.00\n",
            "| 에폭 1 |  반복 301 / 351 | 시간 195[s] | 손실 1.00\n",
            "| 에폭 1 |  반복 321 / 351 | 시간 208[s] | 손실 1.00\n",
            "| 에폭 1 |  반복 341 / 351 | 시간 221[s] | 손실 1.00\n",
            "Q 10/15/94                     \n",
            "T 1994-10-15\n",
            "\u001b[91m☒\u001b[0m 1978-08-11\n",
            "---\n",
            "Q thursday, november 13, 2008  \n",
            "T 2008-11-13\n",
            "\u001b[91m☒\u001b[0m 1978-08-11\n",
            "---\n",
            "Q Mar 25, 2003                 \n",
            "T 2003-03-25\n",
            "\u001b[91m☒\u001b[0m 1978-08-11\n",
            "---\n",
            "Q Tuesday, November 22, 2016   \n",
            "T 2016-11-22\n",
            "\u001b[91m☒\u001b[0m 1978-08-11\n",
            "---\n",
            "Q Saturday, July 18, 1970      \n",
            "T 1970-07-18\n",
            "\u001b[91m☒\u001b[0m 1978-08-11\n",
            "---\n",
            "Q october 6, 1992              \n",
            "T 1992-10-06\n",
            "\u001b[91m☒\u001b[0m 1978-08-11\n",
            "---\n",
            "Q 8/23/08                      \n",
            "T 2008-08-23\n",
            "\u001b[91m☒\u001b[0m 1978-08-11\n",
            "---\n",
            "Q 8/30/07                      \n",
            "T 2007-08-30\n",
            "\u001b[91m☒\u001b[0m 1978-08-11\n",
            "---\n",
            "Q 10/28/13                     \n",
            "T 2013-10-28\n",
            "\u001b[91m☒\u001b[0m 1978-08-11\n",
            "---\n",
            "Q sunday, november 6, 2016     \n",
            "T 2016-11-06\n",
            "\u001b[91m☒\u001b[0m 1978-08-11\n",
            "---\n",
            "정확도 0.000%\n",
            "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 2 |  반복 21 / 351 | 시간 13[s] | 손실 1.00\n",
            "| 에폭 2 |  반복 41 / 351 | 시간 26[s] | 손실 0.99\n",
            "| 에폭 2 |  반복 61 / 351 | 시간 39[s] | 손실 0.99\n",
            "| 에폭 2 |  반복 81 / 351 | 시간 52[s] | 손실 0.99\n",
            "| 에폭 2 |  반복 101 / 351 | 시간 65[s] | 손실 0.99\n",
            "| 에폭 2 |  반복 121 / 351 | 시간 78[s] | 손실 0.99\n",
            "| 에폭 2 |  반복 141 / 351 | 시간 91[s] | 손실 0.98\n",
            "| 에폭 2 |  반복 161 / 351 | 시간 104[s] | 손실 0.98\n",
            "| 에폭 2 |  반복 181 / 351 | 시간 117[s] | 손실 0.97\n",
            "| 에폭 2 |  반복 201 / 351 | 시간 130[s] | 손실 0.95\n",
            "| 에폭 2 |  반복 221 / 351 | 시간 143[s] | 손실 0.94\n",
            "| 에폭 2 |  반복 241 / 351 | 시간 156[s] | 손실 0.90\n",
            "| 에폭 2 |  반복 261 / 351 | 시간 169[s] | 손실 0.83\n",
            "| 에폭 2 |  반복 281 / 351 | 시간 182[s] | 손실 0.74\n",
            "| 에폭 2 |  반복 301 / 351 | 시간 195[s] | 손실 0.66\n",
            "| 에폭 2 |  반복 321 / 351 | 시간 208[s] | 손실 0.58\n",
            "| 에폭 2 |  반복 341 / 351 | 시간 221[s] | 손실 0.47\n",
            "Q 10/15/94                     \n",
            "T 1994-10-15\n",
            "\u001b[92m☑\u001b[0m 1994-10-15\n",
            "---\n",
            "Q thursday, november 13, 2008  \n",
            "T 2008-11-13\n",
            "\u001b[91m☒\u001b[0m 2006-11-13\n",
            "---\n",
            "Q Mar 25, 2003                 \n",
            "T 2003-03-25\n",
            "\u001b[92m☑\u001b[0m 2003-03-25\n",
            "---\n",
            "Q Tuesday, November 22, 2016   \n",
            "T 2016-11-22\n",
            "\u001b[92m☑\u001b[0m 2016-11-22\n",
            "---\n",
            "Q Saturday, July 18, 1970      \n",
            "T 1970-07-18\n",
            "\u001b[92m☑\u001b[0m 1970-07-18\n",
            "---\n",
            "Q october 6, 1992              \n",
            "T 1992-10-06\n",
            "\u001b[92m☑\u001b[0m 1992-10-06\n",
            "---\n",
            "Q 8/23/08                      \n",
            "T 2008-08-23\n",
            "\u001b[92m☑\u001b[0m 2008-08-23\n",
            "---\n",
            "Q 8/30/07                      \n",
            "T 2007-08-30\n",
            "\u001b[91m☒\u001b[0m 2007-08-09\n",
            "---\n",
            "Q 10/28/13                     \n",
            "T 2013-10-28\n",
            "\u001b[91m☒\u001b[0m 1983-10-28\n",
            "---\n",
            "Q sunday, november 6, 2016     \n",
            "T 2016-11-06\n",
            "\u001b[91m☒\u001b[0m 2016-11-08\n",
            "---\n",
            "정확도 51.320%\n",
            "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 3 |  반복 21 / 351 | 시간 13[s] | 손실 0.30\n",
            "| 에폭 3 |  반복 41 / 351 | 시간 26[s] | 손실 0.21\n",
            "| 에폭 3 |  반복 61 / 351 | 시간 39[s] | 손실 0.14\n",
            "| 에폭 3 |  반복 81 / 351 | 시간 52[s] | 손실 0.09\n",
            "| 에폭 3 |  반복 101 / 351 | 시간 65[s] | 손실 0.07\n",
            "| 에폭 3 |  반복 121 / 351 | 시간 78[s] | 손실 0.05\n",
            "| 에폭 3 |  반복 141 / 351 | 시간 91[s] | 손실 0.04\n",
            "| 에폭 3 |  반복 161 / 351 | 시간 104[s] | 손실 0.03\n",
            "| 에폭 3 |  반복 181 / 351 | 시간 117[s] | 손실 0.03\n",
            "| 에폭 3 |  반복 201 / 351 | 시간 130[s] | 손실 0.02\n",
            "| 에폭 3 |  반복 221 / 351 | 시간 143[s] | 손실 0.02\n",
            "| 에폭 3 |  반복 241 / 351 | 시간 157[s] | 손실 0.02\n",
            "| 에폭 3 |  반복 261 / 351 | 시간 170[s] | 손실 0.01\n",
            "| 에폭 3 |  반복 281 / 351 | 시간 183[s] | 손실 0.01\n",
            "| 에폭 3 |  반복 301 / 351 | 시간 196[s] | 손실 0.01\n",
            "| 에폭 3 |  반복 321 / 351 | 시간 209[s] | 손실 0.01\n",
            "| 에폭 3 |  반복 341 / 351 | 시간 222[s] | 손실 0.01\n",
            "Q 10/15/94                     \n",
            "T 1994-10-15\n",
            "\u001b[92m☑\u001b[0m 1994-10-15\n",
            "---\n",
            "Q thursday, november 13, 2008  \n",
            "T 2008-11-13\n",
            "\u001b[92m☑\u001b[0m 2008-11-13\n",
            "---\n",
            "Q Mar 25, 2003                 \n",
            "T 2003-03-25\n",
            "\u001b[92m☑\u001b[0m 2003-03-25\n",
            "---\n",
            "Q Tuesday, November 22, 2016   \n",
            "T 2016-11-22\n",
            "\u001b[92m☑\u001b[0m 2016-11-22\n",
            "---\n",
            "Q Saturday, July 18, 1970      \n",
            "T 1970-07-18\n",
            "\u001b[92m☑\u001b[0m 1970-07-18\n",
            "---\n",
            "Q october 6, 1992              \n",
            "T 1992-10-06\n",
            "\u001b[92m☑\u001b[0m 1992-10-06\n",
            "---\n",
            "Q 8/23/08                      \n",
            "T 2008-08-23\n",
            "\u001b[92m☑\u001b[0m 2008-08-23\n",
            "---\n",
            "Q 8/30/07                      \n",
            "T 2007-08-30\n",
            "\u001b[92m☑\u001b[0m 2007-08-30\n",
            "---\n",
            "Q 10/28/13                     \n",
            "T 2013-10-28\n",
            "\u001b[92m☑\u001b[0m 2013-10-28\n",
            "---\n",
            "Q sunday, november 6, 2016     \n",
            "T 2016-11-06\n",
            "\u001b[92m☑\u001b[0m 2016-11-06\n",
            "---\n",
            "정확도 99.900%\n",
            "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 0.01\n",
            "| 에폭 4 |  반복 21 / 351 | 시간 13[s] | 손실 0.01\n",
            "| 에폭 4 |  반복 41 / 351 | 시간 26[s] | 손실 0.01\n",
            "| 에폭 4 |  반복 61 / 351 | 시간 39[s] | 손실 0.01\n",
            "| 에폭 4 |  반복 81 / 351 | 시간 52[s] | 손실 0.01\n",
            "| 에폭 4 |  반복 101 / 351 | 시간 65[s] | 손실 0.01\n",
            "| 에폭 4 |  반복 121 / 351 | 시간 78[s] | 손실 0.00\n",
            "| 에폭 4 |  반복 141 / 351 | 시간 91[s] | 손실 0.01\n",
            "| 에폭 4 |  반복 161 / 351 | 시간 104[s] | 손실 0.00\n",
            "| 에폭 4 |  반복 181 / 351 | 시간 117[s] | 손실 0.00\n",
            "| 에폭 4 |  반복 201 / 351 | 시간 130[s] | 손실 0.00\n",
            "| 에폭 4 |  반복 221 / 351 | 시간 143[s] | 손실 0.00\n",
            "| 에폭 4 |  반복 241 / 351 | 시간 156[s] | 손실 0.00\n",
            "| 에폭 4 |  반복 261 / 351 | 시간 169[s] | 손실 0.00\n",
            "| 에폭 4 |  반복 281 / 351 | 시간 182[s] | 손실 0.00\n",
            "| 에폭 4 |  반복 301 / 351 | 시간 195[s] | 손실 0.00\n",
            "| 에폭 4 |  반복 321 / 351 | 시간 208[s] | 손실 0.00\n",
            "| 에폭 4 |  반복 341 / 351 | 시간 221[s] | 손실 0.00\n",
            "Q 10/15/94                     \n",
            "T 1994-10-15\n",
            "\u001b[92m☑\u001b[0m 1994-10-15\n",
            "---\n",
            "Q thursday, november 13, 2008  \n",
            "T 2008-11-13\n",
            "\u001b[92m☑\u001b[0m 2008-11-13\n",
            "---\n",
            "Q Mar 25, 2003                 \n",
            "T 2003-03-25\n",
            "\u001b[92m☑\u001b[0m 2003-03-25\n",
            "---\n",
            "Q Tuesday, November 22, 2016   \n",
            "T 2016-11-22\n",
            "\u001b[92m☑\u001b[0m 2016-11-22\n",
            "---\n",
            "Q Saturday, July 18, 1970      \n",
            "T 1970-07-18\n",
            "\u001b[92m☑\u001b[0m 1970-07-18\n",
            "---\n",
            "Q october 6, 1992              \n",
            "T 1992-10-06\n",
            "\u001b[92m☑\u001b[0m 1992-10-06\n",
            "---\n",
            "Q 8/23/08                      \n",
            "T 2008-08-23\n",
            "\u001b[92m☑\u001b[0m 2008-08-23\n",
            "---\n",
            "Q 8/30/07                      \n",
            "T 2007-08-30\n",
            "\u001b[92m☑\u001b[0m 2007-08-30\n",
            "---\n",
            "Q 10/28/13                     \n",
            "T 2013-10-28\n",
            "\u001b[92m☑\u001b[0m 2013-10-28\n",
            "---\n",
            "Q sunday, november 6, 2016     \n",
            "T 2016-11-06\n",
            "\u001b[92m☑\u001b[0m 2016-11-06\n",
            "---\n",
            "정확도 99.900%\n",
            "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 21 / 351 | 시간 13[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 41 / 351 | 시간 26[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 61 / 351 | 시간 39[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 81 / 351 | 시간 52[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 101 / 351 | 시간 65[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 121 / 351 | 시간 79[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 141 / 351 | 시간 91[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 161 / 351 | 시간 104[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 181 / 351 | 시간 118[s] | 손실 0.02\n",
            "| 에폭 5 |  반복 201 / 351 | 시간 131[s] | 손실 0.01\n",
            "| 에폭 5 |  반복 221 / 351 | 시간 144[s] | 손실 0.01\n",
            "| 에폭 5 |  반복 241 / 351 | 시간 157[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 261 / 351 | 시간 170[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 281 / 351 | 시간 183[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 301 / 351 | 시간 196[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 321 / 351 | 시간 209[s] | 손실 0.00\n",
            "| 에폭 5 |  반복 341 / 351 | 시간 222[s] | 손실 0.00\n",
            "Q 10/15/94                     \n",
            "T 1994-10-15\n",
            "\u001b[92m☑\u001b[0m 1994-10-15\n",
            "---\n",
            "Q thursday, november 13, 2008  \n",
            "T 2008-11-13\n",
            "\u001b[92m☑\u001b[0m 2008-11-13\n",
            "---\n",
            "Q Mar 25, 2003                 \n",
            "T 2003-03-25\n",
            "\u001b[92m☑\u001b[0m 2003-03-25\n",
            "---\n",
            "Q Tuesday, November 22, 2016   \n",
            "T 2016-11-22\n",
            "\u001b[92m☑\u001b[0m 2016-11-22\n",
            "---\n",
            "Q Saturday, July 18, 1970      \n",
            "T 1970-07-18\n",
            "\u001b[92m☑\u001b[0m 1970-07-18\n",
            "---\n",
            "Q october 6, 1992              \n",
            "T 1992-10-06\n",
            "\u001b[92m☑\u001b[0m 1992-10-06\n",
            "---\n",
            "Q 8/23/08                      \n",
            "T 2008-08-23\n",
            "\u001b[92m☑\u001b[0m 2008-08-23\n",
            "---\n",
            "Q 8/30/07                      \n",
            "T 2007-08-30\n",
            "\u001b[92m☑\u001b[0m 2007-08-30\n",
            "---\n",
            "Q 10/28/13                     \n",
            "T 2013-10-28\n",
            "\u001b[92m☑\u001b[0m 2013-10-28\n",
            "---\n",
            "Q sunday, november 6, 2016     \n",
            "T 2016-11-06\n",
            "\u001b[92m☑\u001b[0m 2016-11-06\n",
            "---\n",
            "정확도 100.000%\n",
            "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 21 / 351 | 시간 13[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 41 / 351 | 시간 26[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 61 / 351 | 시간 39[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 81 / 351 | 시간 52[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 101 / 351 | 시간 64[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 121 / 351 | 시간 77[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 141 / 351 | 시간 90[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 161 / 351 | 시간 103[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 181 / 351 | 시간 116[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 201 / 351 | 시간 128[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 221 / 351 | 시간 141[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 241 / 351 | 시간 154[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 261 / 351 | 시간 167[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 281 / 351 | 시간 180[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 301 / 351 | 시간 193[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 321 / 351 | 시간 205[s] | 손실 0.00\n",
            "| 에폭 6 |  반복 341 / 351 | 시간 218[s] | 손실 0.00\n",
            "Q 10/15/94                     \n",
            "T 1994-10-15\n",
            "\u001b[92m☑\u001b[0m 1994-10-15\n",
            "---\n",
            "Q thursday, november 13, 2008  \n",
            "T 2008-11-13\n",
            "\u001b[92m☑\u001b[0m 2008-11-13\n",
            "---\n",
            "Q Mar 25, 2003                 \n",
            "T 2003-03-25\n",
            "\u001b[92m☑\u001b[0m 2003-03-25\n",
            "---\n",
            "Q Tuesday, November 22, 2016   \n",
            "T 2016-11-22\n",
            "\u001b[92m☑\u001b[0m 2016-11-22\n",
            "---\n",
            "Q Saturday, July 18, 1970      \n",
            "T 1970-07-18\n",
            "\u001b[92m☑\u001b[0m 1970-07-18\n",
            "---\n",
            "Q october 6, 1992              \n",
            "T 1992-10-06\n",
            "\u001b[92m☑\u001b[0m 1992-10-06\n",
            "---\n",
            "Q 8/23/08                      \n",
            "T 2008-08-23\n",
            "\u001b[92m☑\u001b[0m 2008-08-23\n",
            "---\n",
            "Q 8/30/07                      \n",
            "T 2007-08-30\n",
            "\u001b[92m☑\u001b[0m 2007-08-30\n",
            "---\n",
            "Q 10/28/13                     \n",
            "T 2013-10-28\n",
            "\u001b[92m☑\u001b[0m 2013-10-28\n",
            "---\n",
            "Q sunday, november 6, 2016     \n",
            "T 2016-11-06\n",
            "\u001b[92m☑\u001b[0m 2016-11-06\n",
            "---\n",
            "정확도 100.000%\n",
            "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 21 / 351 | 시간 13[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 41 / 351 | 시간 26[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 61 / 351 | 시간 38[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 81 / 351 | 시간 51[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 101 / 351 | 시간 64[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 121 / 351 | 시간 77[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 141 / 351 | 시간 90[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 161 / 351 | 시간 102[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 181 / 351 | 시간 115[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 201 / 351 | 시간 128[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 221 / 351 | 시간 141[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 241 / 351 | 시간 154[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 261 / 351 | 시간 167[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 281 / 351 | 시간 180[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 301 / 351 | 시간 192[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 321 / 351 | 시간 205[s] | 손실 0.00\n",
            "| 에폭 7 |  반복 341 / 351 | 시간 218[s] | 손실 0.00\n",
            "Q 10/15/94                     \n",
            "T 1994-10-15\n",
            "\u001b[92m☑\u001b[0m 1994-10-15\n",
            "---\n",
            "Q thursday, november 13, 2008  \n",
            "T 2008-11-13\n",
            "\u001b[92m☑\u001b[0m 2008-11-13\n",
            "---\n",
            "Q Mar 25, 2003                 \n",
            "T 2003-03-25\n",
            "\u001b[92m☑\u001b[0m 2003-03-25\n",
            "---\n",
            "Q Tuesday, November 22, 2016   \n",
            "T 2016-11-22\n",
            "\u001b[92m☑\u001b[0m 2016-11-22\n",
            "---\n",
            "Q Saturday, July 18, 1970      \n",
            "T 1970-07-18\n",
            "\u001b[92m☑\u001b[0m 1970-07-18\n",
            "---\n",
            "Q october 6, 1992              \n",
            "T 1992-10-06\n",
            "\u001b[92m☑\u001b[0m 1992-10-06\n",
            "---\n",
            "Q 8/23/08                      \n",
            "T 2008-08-23\n",
            "\u001b[92m☑\u001b[0m 2008-08-23\n",
            "---\n",
            "Q 8/30/07                      \n",
            "T 2007-08-30\n",
            "\u001b[92m☑\u001b[0m 2007-08-30\n",
            "---\n",
            "Q 10/28/13                     \n",
            "T 2013-10-28\n",
            "\u001b[92m☑\u001b[0m 2013-10-28\n",
            "---\n",
            "Q sunday, november 6, 2016     \n",
            "T 2016-11-06\n",
            "\u001b[92m☑\u001b[0m 2016-11-06\n",
            "---\n",
            "정확도 100.000%\n",
            "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 21 / 351 | 시간 13[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 41 / 351 | 시간 26[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 61 / 351 | 시간 39[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 81 / 351 | 시간 52[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 101 / 351 | 시간 65[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 121 / 351 | 시간 77[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 141 / 351 | 시간 90[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 161 / 351 | 시간 103[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 181 / 351 | 시간 116[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 201 / 351 | 시간 128[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 221 / 351 | 시간 141[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 241 / 351 | 시간 154[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 261 / 351 | 시간 167[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 281 / 351 | 시간 180[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 301 / 351 | 시간 193[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 321 / 351 | 시간 206[s] | 손실 0.00\n",
            "| 에폭 8 |  반복 341 / 351 | 시간 219[s] | 손실 0.00\n",
            "Q 10/15/94                     \n",
            "T 1994-10-15\n",
            "\u001b[92m☑\u001b[0m 1994-10-15\n",
            "---\n",
            "Q thursday, november 13, 2008  \n",
            "T 2008-11-13\n",
            "\u001b[92m☑\u001b[0m 2008-11-13\n",
            "---\n",
            "Q Mar 25, 2003                 \n",
            "T 2003-03-25\n",
            "\u001b[92m☑\u001b[0m 2003-03-25\n",
            "---\n",
            "Q Tuesday, November 22, 2016   \n",
            "T 2016-11-22\n",
            "\u001b[92m☑\u001b[0m 2016-11-22\n",
            "---\n",
            "Q Saturday, July 18, 1970      \n",
            "T 1970-07-18\n",
            "\u001b[92m☑\u001b[0m 1970-07-18\n",
            "---\n",
            "Q october 6, 1992              \n",
            "T 1992-10-06\n",
            "\u001b[92m☑\u001b[0m 1992-10-06\n",
            "---\n",
            "Q 8/23/08                      \n",
            "T 2008-08-23\n",
            "\u001b[92m☑\u001b[0m 2008-08-23\n",
            "---\n",
            "Q 8/30/07                      \n",
            "T 2007-08-30\n",
            "\u001b[92m☑\u001b[0m 2007-08-30\n",
            "---\n",
            "Q 10/28/13                     \n",
            "T 2013-10-28\n",
            "\u001b[92m☑\u001b[0m 2013-10-28\n",
            "---\n",
            "Q sunday, november 6, 2016     \n",
            "T 2016-11-06\n",
            "\u001b[92m☑\u001b[0m 2016-11-06\n",
            "---\n",
            "정확도 100.000%\n",
            "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 21 / 351 | 시간 13[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 41 / 351 | 시간 26[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 61 / 351 | 시간 40[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 81 / 351 | 시간 53[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 101 / 351 | 시간 66[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 121 / 351 | 시간 79[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 141 / 351 | 시간 92[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 161 / 351 | 시간 105[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 181 / 351 | 시간 118[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 201 / 351 | 시간 131[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 221 / 351 | 시간 144[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 241 / 351 | 시간 157[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 261 / 351 | 시간 170[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 281 / 351 | 시간 183[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 301 / 351 | 시간 196[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 321 / 351 | 시간 210[s] | 손실 0.00\n",
            "| 에폭 9 |  반복 341 / 351 | 시간 223[s] | 손실 0.00\n",
            "Q 10/15/94                     \n",
            "T 1994-10-15\n",
            "\u001b[92m☑\u001b[0m 1994-10-15\n",
            "---\n",
            "Q thursday, november 13, 2008  \n",
            "T 2008-11-13\n",
            "\u001b[92m☑\u001b[0m 2008-11-13\n",
            "---\n",
            "Q Mar 25, 2003                 \n",
            "T 2003-03-25\n",
            "\u001b[92m☑\u001b[0m 2003-03-25\n",
            "---\n",
            "Q Tuesday, November 22, 2016   \n",
            "T 2016-11-22\n",
            "\u001b[92m☑\u001b[0m 2016-11-22\n",
            "---\n",
            "Q Saturday, July 18, 1970      \n",
            "T 1970-07-18\n",
            "\u001b[92m☑\u001b[0m 1970-07-18\n",
            "---\n",
            "Q october 6, 1992              \n",
            "T 1992-10-06\n",
            "\u001b[92m☑\u001b[0m 1992-10-06\n",
            "---\n",
            "Q 8/23/08                      \n",
            "T 2008-08-23\n",
            "\u001b[92m☑\u001b[0m 2008-08-23\n",
            "---\n",
            "Q 8/30/07                      \n",
            "T 2007-08-30\n",
            "\u001b[92m☑\u001b[0m 2007-08-30\n",
            "---\n",
            "Q 10/28/13                     \n",
            "T 2013-10-28\n",
            "\u001b[92m☑\u001b[0m 2013-10-28\n",
            "---\n",
            "Q sunday, november 6, 2016     \n",
            "T 2016-11-06\n",
            "\u001b[92m☑\u001b[0m 2016-11-06\n",
            "---\n",
            "정확도 100.000%\n",
            "| 에폭 10 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 21 / 351 | 시간 13[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 41 / 351 | 시간 27[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 61 / 351 | 시간 40[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 81 / 351 | 시간 54[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 101 / 351 | 시간 67[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 121 / 351 | 시간 80[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 141 / 351 | 시간 94[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 161 / 351 | 시간 107[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 181 / 351 | 시간 120[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 201 / 351 | 시간 134[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 221 / 351 | 시간 147[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 241 / 351 | 시간 160[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 261 / 351 | 시간 174[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 281 / 351 | 시간 187[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 301 / 351 | 시간 200[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 321 / 351 | 시간 214[s] | 손실 0.00\n",
            "| 에폭 10 |  반복 341 / 351 | 시간 227[s] | 손실 0.00\n",
            "Q 10/15/94                     \n",
            "T 1994-10-15\n",
            "\u001b[92m☑\u001b[0m 1994-10-15\n",
            "---\n",
            "Q thursday, november 13, 2008  \n",
            "T 2008-11-13\n",
            "\u001b[92m☑\u001b[0m 2008-11-13\n",
            "---\n",
            "Q Mar 25, 2003                 \n",
            "T 2003-03-25\n",
            "\u001b[92m☑\u001b[0m 2003-03-25\n",
            "---\n",
            "Q Tuesday, November 22, 2016   \n",
            "T 2016-11-22\n",
            "\u001b[92m☑\u001b[0m 2016-11-22\n",
            "---\n",
            "Q Saturday, July 18, 1970      \n",
            "T 1970-07-18\n",
            "\u001b[92m☑\u001b[0m 1970-07-18\n",
            "---\n",
            "Q october 6, 1992              \n",
            "T 1992-10-06\n",
            "\u001b[92m☑\u001b[0m 1992-10-06\n",
            "---\n",
            "Q 8/23/08                      \n",
            "T 2008-08-23\n",
            "\u001b[92m☑\u001b[0m 2008-08-23\n",
            "---\n",
            "Q 8/30/07                      \n",
            "T 2007-08-30\n",
            "\u001b[92m☑\u001b[0m 2007-08-30\n",
            "---\n",
            "Q 10/28/13                     \n",
            "T 2013-10-28\n",
            "\u001b[92m☑\u001b[0m 2013-10-28\n",
            "---\n",
            "Q sunday, november 6, 2016     \n",
            "T 2016-11-06\n",
            "\u001b[92m☑\u001b[0m 2016-11-06\n",
            "---\n",
            "정확도 100.000%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50640 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54253 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51221 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54869 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46020 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50640 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54253 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51221 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54869 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46020 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G35P5M8udvUj"
      },
      "source": [
        "# 어테션 가중치의 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4gx2N7zadu4s",
        "outputId": "f8454d2a-c06f-4c3c-c72d-97a01182360e"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import numpy as np\n",
        "from dataset import sequence\n",
        "import matplotlib.pyplot as plt\n",
        "from Chap08_Attention.attention_seq2seq import AttentionSeq2seq\n",
        "\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = \\\n",
        "    sequence.load_data('date.txt')\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "# 입력 문장 반전\n",
        "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
        "\n",
        "vocab_size = len(char_to_id)\n",
        "wordvec_size = 16\n",
        "hidden_size = 256\n",
        "\n",
        "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "model.load_params()\n",
        "\n",
        "_idx = 0\n",
        "def visualize(attention_map, row_labels, column_labels):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pcolor(attention_map, cmap=plt.cm.Greys_r, vmin=0.0, vmax=1.0)\n",
        "\n",
        "    ax.patch.set_facecolor('black')\n",
        "    ax.set_yticks(np.arange(attention_map.shape[0])+0.5, minor=False)\n",
        "    ax.set_xticks(np.arange(attention_map.shape[1])+0.5, minor=False)\n",
        "    ax.invert_yaxis()\n",
        "    ax.set_xticklabels(row_labels, minor=False)\n",
        "    ax.set_yticklabels(column_labels, minor=False)\n",
        "\n",
        "    global _idx\n",
        "    _idx += 1\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "np.random.seed(1984)\n",
        "for _ in range(5):\n",
        "    idx = [np.random.randint(0, len(x_test))]\n",
        "    x = x_test[idx]\n",
        "    t = t_test[idx]\n",
        "\n",
        "    model.forward(x, t)\n",
        "    d = model.decoder.attention.attention_weights\n",
        "    d = np.array(d)\n",
        "    attention_map = d.reshape(d.shape[0], d.shape[2])\n",
        "\n",
        "    # 출력하기 위해 반전\n",
        "    attention_map = attention_map[:,::-1]\n",
        "    x = x[:,::-1]\n",
        "\n",
        "    row_labels = [id_to_char[i] for i in x[0]]\n",
        "    column_labels = [id_to_char[i] for i in t[0]]\n",
        "    column_labels = column_labels[1:]\n",
        "\n",
        "    visualize(attention_map, row_labels, column_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hevDf8Nd85s"
      },
      "source": [
        "# 넘파이 인덱싱과 친해지기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WWot1Bbix4A",
        "outputId": "43cd10bf-dda8-4ed1-cf86-4bd297c402e3"
      },
      "source": [
        "import numpy as np\n",
        "# 파이썬 3차원 배열 [Layer][Row][Column]\n",
        "\n",
        "x = np.array([[[1],[2],[3]], [[4],[5],[6]]])\n",
        "# ellipsis\n",
        "print(x)\n",
        "print(x[...,0])\n",
        "print(x.shape)\n",
        "print(x[1:2].shape)\n",
        "print(x[1:2])\n",
        "print()\n",
        "print(x[0,:,0])\n",
        "print(x[:, -1, :])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1]\n",
            "  [2]\n",
            "  [3]]\n",
            "\n",
            " [[4]\n",
            "  [5]\n",
            "  [6]]]\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "(2, 3, 1)\n",
            "(1, 3, 1)\n",
            "[[[4]\n",
            "  [5]\n",
            "  [6]]]\n",
            "\n",
            "[1 2 3]\n",
            "[[3]\n",
            " [6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6C9nct4d6_4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}